{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAGAS Evaluation of Indian Legal Assistant RAG Model\n",
    "\n",
    "This notebook evaluates the performance of our Indian Legal Assistant chatbot using RAGAS (Retrieval-Augmented Generation Assessment) framework. The evaluation covers multiple metrics to assess the quality of retrieval and generation components.\n",
    "\n",
    "## Evaluation Metrics\n",
    "\n",
    "- **Faithfulness**: Measures how grounded the answer is in the retrieved context\n",
    "- **Answer Relevancy**: Evaluates how relevant the answer is to the question\n",
    "- **Context Precision**: Assesses the relevance of retrieved context to the question\n",
    "- **Context Recall**: Measures how well retrieval captures all relevant information\n",
    "- **Answer Correctness**: Evaluates factual accuracy of generated answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ragas\n",
      "  Downloading ragas-0.3.4-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.2-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.6-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from ragas) (2.2.6)\n",
      "Collecting tiktoken (from ragas)\n",
      "  Downloading tiktoken-0.11.0-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from ragas) (2.11.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from ragas) (1.6.0)\n",
      "Collecting appdirs (from ragas)\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting diskcache>=5.6.3 (from ragas)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting typer (from ragas)\n",
      "  Downloading typer-0.17.4-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting rich (from ragas)\n",
      "  Using cached rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting openai>=1.0.0 (from ragas)\n",
      "  Downloading openai-1.107.3-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from ragas) (4.67.1)\n",
      "Collecting instructor (from ragas)\n",
      "  Downloading instructor-1.11.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gitpython (from ragas)\n",
      "  Using cached gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pillow>=10.4.0 (from ragas)\n",
      "  Using cached pillow-11.3.0-cp310-cp310-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from ragas) (3.4.2)\n",
      "Collecting scikit-network (from ragas)\n",
      "  Downloading scikit_network-0.33.3-cp310-cp310-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting langchain (from ragas)\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core (from ragas)\n",
      "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting langchain-community (from ragas)\n",
      "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain_openai (from ragas)\n",
      "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Using cached pyarrow-21.0.0-cp310-cp310-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from datasets) (2.32.4)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from datasets) (0.33.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohttp-3.12.15-cp310-cp310-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.2-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.60.0-cp310-cp310-win_amd64.whl.metadata (113 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp310-cp310-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.4-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached frozenlist-1.7.0-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached multidict-6.6.4-cp310-cp310-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached propcache-0.3.2-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached yarl-1.20.1-cp310-cp310-win_amd64.whl.metadata (76 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from openai>=1.0.0->ragas) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.0.0->ragas)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from openai>=1.0.0->ragas) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.0.0->ragas)\n",
      "  Downloading jiter-0.11.0-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from openai>=1.0.0->ragas) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.0.0->ragas) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->ragas) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->ragas) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->ragas) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from pydantic>=2.0.0->ragas) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from pydantic>=2.0.0->ragas) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from pydantic>=2.0.0->ragas) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from tqdm->ragas) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython->ragas)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->ragas)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting docstring-parser<1.0,>=0.16 (from instructor->ragas)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from instructor->ragas) (3.1.6)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.0.0->ragas)\n",
      "  Using cached jiter-0.10.0-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting tenacity<10.0.0,>=8.2.3 (from instructor->ragas)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from jinja2<4.0.0,>=3.1.4->instructor->ragas) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->ragas)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from rich->ragas) (2.19.2)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from typer->ragas) (8.2.1)\n",
      "Collecting shellingham>=1.3.0 (from typer->ragas)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->ragas)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain->ragas)\n",
      "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain->ragas)\n",
      "  Downloading langsmith-0.4.28-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain->ragas)\n",
      "  Using cached sqlalchemy-2.0.43-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core->ragas)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain->ragas)\n",
      "  Using cached greenlet-3.2.4-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.1.17->langchain->ragas)\n",
      "  Using cached orjson-3.11.3-cp310-cp310-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain->ragas)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain->ragas)\n",
      "  Downloading zstandard-0.25.0-cp310-cp310-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community->ragas)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community->ragas)\n",
      "  Using cached pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community->ragas)\n",
      "  Using cached httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community->ragas)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community->ragas)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community->ragas)\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community->ragas)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\upama\\anaconda3\\envs\\word\\lib\\site-packages (from tiktoken->ragas) (2024.11.6)\n",
      "Collecting scipy>=1.7.3 (from scikit-network->ragas)\n",
      "  Using cached scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Downloading ragas-0.3.4-py3-none-any.whl (279 kB)\n",
      "Downloading datasets-4.1.0-py3-none-any.whl (503 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Using cached pandas-2.3.2-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "Downloading matplotlib-3.10.6-cp310-cp310-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/8.1 MB 3.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.3/8.1 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.4/8.1 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.1/8.1 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.9/8.1 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.5/8.1 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.7/8.1 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.2/8.1 MB 3.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.0/8.1 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.6/8.1 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.3/8.1 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.6/8.1 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.9/8.1 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 2.7 MB/s eta 0:00:00\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached aiohttp-3.12.15-cp310-cp310-win_amd64.whl (452 kB)\n",
      "Using cached multidict-6.6.4-cp310-cp310-win_amd64.whl (46 kB)\n",
      "Using cached yarl-1.20.1-cp310-cp310-win_amd64.whl (86 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached contourpy-1.3.2-cp310-cp310-win_amd64.whl (221 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading fonttools-4.60.0-cp310-cp310-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.3/2.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 3.9 MB/s eta 0:00:00\n",
      "Using cached frozenlist-1.7.0-cp310-cp310-win_amd64.whl (43 kB)\n",
      "Using cached kiwisolver-1.4.9-cp310-cp310-win_amd64.whl (73 kB)\n",
      "Downloading openai-1.107.3-py3-none-any.whl (947 kB)\n",
      "   ---------------------------------------- 0.0/947.6 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/947.6 kB ? eta -:--:--\n",
      "   ---------------------- ----------------- 524.3/947.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 947.6/947.6 kB 1.5 MB/s eta 0:00:00\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached pillow-11.3.0-cp310-cp310-win_amd64.whl (7.0 MB)\n",
      "Using cached propcache-0.3.2-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Using cached pyarrow-21.0.0-cp310-cp310-win_amd64.whl (26.2 MB)\n",
      "Downloading pyparsing-3.2.4-py3-none-any.whl (113 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading instructor-1.11.3-py3-none-any.whl (155 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Using cached jiter-0.10.0-cp310-cp310-win_amd64.whl (207 kB)\n",
      "Using cached rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading typer-0.17.4-py3-none-any.whl (46 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 0.8/1.0 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 2.3 MB/s eta 0:00:00\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Using cached sqlalchemy-2.0.43-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "Using cached greenlet-3.2.4-cp310-cp310-win_amd64.whl (298 kB)\n",
      "Downloading langsmith-0.4.28-py3-none-any.whl (384 kB)\n",
      "Using cached orjson-3.11.3-cp310-cp310-win_amd64.whl (131 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading zstandard-0.25.0-cp310-cp310-win_amd64.whl (506 kB)\n",
      "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.5 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.8/2.5 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.3/2.5 MB 1.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.1/2.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 2.3 MB/s eta 0:00:00\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
      "Downloading tiktoken-0.11.0-cp310-cp310-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.2 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 786.4/884.2 kB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 884.2/884.2 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading scikit_network-0.33.3-cp310-cp310-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.3/2.7 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.1/2.7 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 3.7 MB/s eta 0:00:00\n",
      "Using cached scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-win_amd64.whl (30 kB)\n",
      "Installing collected packages: pytz, appdirs, zstandard, xxhash, tzdata, tenacity, smmap, shellingham, scipy, requests, python-dotenv, pyparsing, pyarrow, propcache, pillow, orjson, mypy-extensions, multidict, mdurl, marshmallow, kiwisolver, jsonpatch, jiter, httpx-sse, greenlet, frozenlist, fonttools, docstring-parser, distro, diskcache, dill, cycler, contourpy, async-timeout, aiohappyeyeballs, yarl, typing-inspect, tiktoken, SQLAlchemy, scikit-network, requests-toolbelt, pandas, multiprocess, matplotlib, markdown-it-py, gitdb, aiosignal, seaborn, rich, pydantic-settings, gitpython, dataclasses-json, aiohttp, typer, openai, langsmith, langchain-core, instructor, datasets, langchain-text-splitters, langchain_openai, langchain, langchain-community, ragas\n",
      "\n",
      "   ----------------------------------------  0/64 [pytz]\n",
      "   ----------------------------------------  0/64 [pytz]\n",
      "   ----------------------------------------  0/64 [pytz]\n",
      "   ----------------------------------------  0/64 [pytz]\n",
      "   - --------------------------------------  2/64 [zstandard]\n",
      "   -- -------------------------------------  4/64 [tzdata]\n",
      "   -- -------------------------------------  4/64 [tzdata]\n",
      "   -- -------------------------------------  4/64 [tzdata]\n",
      "   -- -------------------------------------  4/64 [tzdata]\n",
      "   -- -------------------------------------  4/64 [tzdata]\n",
      "   -- -------------------------------------  4/64 [tzdata]\n",
      "   --- ------------------------------------  5/64 [tenacity]\n",
      "   ---- -----------------------------------  7/64 [shellingham]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "  Attempting uninstall: requests\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "    Found existing installation: requests 2.32.4\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "    Uninstalling requests-2.32.4:\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "      Successfully uninstalled requests-2.32.4\n",
      "   ----- ----------------------------------  8/64 [scipy]\n",
      "   ----- ----------------------------------  9/64 [requests]\n",
      "   ------ --------------------------------- 11/64 [pyparsing]\n",
      "   ------- -------------------------------- 12/64 [pyarrow]\n",
      "   ------- -------------------------------- 12/64 [pyarrow]\n",
      "   ------- -------------------------------- 12/64 [pyarrow]\n",
      "   ------- -------------------------------- 12/64 [pyarrow]\n",
      "   ------- -------------------------------- 12/64 [pyarrow]\n",
      "   ------- -------------------------------- 12/64 [pyarrow]\n",
      "   ------- -------------------------------- 12/64 [pyarrow]\n",
      "   ------- -------------------------------- 12/64 [pyarrow]\n",
      "   ------- -------------------------------- 12/64 [pyarrow]\n",
      "   ------- -------------------------------- 12/64 [pyarrow]\n",
      "   ------- -------------------------------- 12/64 [pyarrow]\n",
      "   ------- -------------------------------- 12/64 [pyarrow]\n",
      "   ------- -------------------------------- 12/64 [pyarrow]\n",
      "   ------- -------------------------------- 12/64 [pyarrow]\n",
      "   -------- ------------------------------- 14/64 [pillow]\n",
      "   -------- ------------------------------- 14/64 [pillow]\n",
      "   -------- ------------------------------- 14/64 [pillow]\n",
      "   -------- ------------------------------- 14/64 [pillow]\n",
      "   -------- ------------------------------- 14/64 [pillow]\n",
      "   ----------- ---------------------------- 18/64 [mdurl]\n",
      "   ------------ --------------------------- 20/64 [kiwisolver]\n",
      "   -------------- ------------------------- 23/64 [httpx-sse]\n",
      "   --------------- ------------------------ 24/64 [greenlet]\n",
      "   ---------------- ----------------------- 26/64 [fonttools]\n",
      "   ---------------- ----------------------- 26/64 [fonttools]\n",
      "   ---------------- ----------------------- 26/64 [fonttools]\n",
      "   ---------------- ----------------------- 26/64 [fonttools]\n",
      "   ---------------- ----------------------- 26/64 [fonttools]\n",
      "   ---------------- ----------------------- 26/64 [fonttools]\n",
      "   ---------------- ----------------------- 26/64 [fonttools]\n",
      "   ---------------- ----------------------- 26/64 [fonttools]\n",
      "   ---------------- ----------------------- 26/64 [fonttools]\n",
      "   ---------------- ----------------------- 26/64 [fonttools]\n",
      "   ---------------- ----------------------- 26/64 [fonttools]\n",
      "   ---------------- ----------------------- 26/64 [fonttools]\n",
      "   ---------------- ----------------------- 26/64 [fonttools]\n",
      "   ---------------- ----------------------- 26/64 [fonttools]\n",
      "   ---------------- ----------------------- 26/64 [fonttools]\n",
      "   ----------------- ---------------------- 28/64 [distro]\n",
      "   ------------------ --------------------- 30/64 [dill]\n",
      "   ------------------ --------------------- 30/64 [dill]\n",
      "   -------------------- ------------------- 32/64 [contourpy]\n",
      "   --------------------- ------------------ 35/64 [yarl]\n",
      "   ----------------------- ---------------- 38/64 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 38/64 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 38/64 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 38/64 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 38/64 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 38/64 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 38/64 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 38/64 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 38/64 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 38/64 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 38/64 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 38/64 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 38/64 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 38/64 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 38/64 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 38/64 [SQLAlchemy]\n",
      "   ------------------------ --------------- 39/64 [scikit-network]\n",
      "   ------------------------ --------------- 39/64 [scikit-network]\n",
      "   ------------------------ --------------- 39/64 [scikit-network]\n",
      "   ------------------------ --------------- 39/64 [scikit-network]\n",
      "   ------------------------ --------------- 39/64 [scikit-network]\n",
      "   ------------------------ --------------- 39/64 [scikit-network]\n",
      "   ------------------------ --------------- 39/64 [scikit-network]\n",
      "   ------------------------ --------------- 39/64 [scikit-network]\n",
      "   ------------------------- -------------- 40/64 [requests-toolbelt]\n",
      "   ------------------------- -------------- 40/64 [requests-toolbelt]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   ------------------------- -------------- 41/64 [pandas]\n",
      "   -------------------------- ------------- 42/64 [multiprocess]\n",
      "   -------------------------- ------------- 42/64 [multiprocess]\n",
      "   -------------------------- ------------- 42/64 [multiprocess]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   -------------------------- ------------- 43/64 [matplotlib]\n",
      "   --------------------------- ------------ 44/64 [markdown-it-py]\n",
      "   --------------------------- ------------ 44/64 [markdown-it-py]\n",
      "   ---------------------------- ----------- 45/64 [gitdb]\n",
      "   ----------------------------- ---------- 47/64 [seaborn]\n",
      "   ----------------------------- ---------- 47/64 [seaborn]\n",
      "   ----------------------------- ---------- 47/64 [seaborn]\n",
      "   ------------------------------ --------- 48/64 [rich]\n",
      "   ------------------------------ --------- 48/64 [rich]\n",
      "   ------------------------------ --------- 48/64 [rich]\n",
      "   ------------------------------ --------- 48/64 [rich]\n",
      "   ------------------------------ --------- 49/64 [pydantic-settings]\n",
      "   ------------------------------- -------- 50/64 [gitpython]\n",
      "   ------------------------------- -------- 51/64 [dataclasses-json]\n",
      "   -------------------------------- ------- 52/64 [aiohttp]\n",
      "   -------------------------------- ------- 52/64 [aiohttp]\n",
      "   -------------------------------- ------- 52/64 [aiohttp]\n",
      "   --------------------------------- ------ 53/64 [typer]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   --------------------------------- ------ 54/64 [openai]\n",
      "   ---------------------------------- ----- 55/64 [langsmith]\n",
      "   ---------------------------------- ----- 55/64 [langsmith]\n",
      "   ---------------------------------- ----- 55/64 [langsmith]\n",
      "   ----------------------------------- ---- 56/64 [langchain-core]\n",
      "   ----------------------------------- ---- 56/64 [langchain-core]\n",
      "   ----------------------------------- ---- 56/64 [langchain-core]\n",
      "   ----------------------------------- ---- 56/64 [langchain-core]\n",
      "   ----------------------------------- ---- 56/64 [langchain-core]\n",
      "   ----------------------------------- ---- 56/64 [langchain-core]\n",
      "   ----------------------------------- ---- 57/64 [instructor]\n",
      "   ----------------------------------- ---- 57/64 [instructor]\n",
      "   ----------------------------------- ---- 57/64 [instructor]\n",
      "   ----------------------------------- ---- 57/64 [instructor]\n",
      "   ------------------------------------ --- 58/64 [datasets]\n",
      "   ------------------------------------ --- 58/64 [datasets]\n",
      "   ------------------------------------ --- 58/64 [datasets]\n",
      "   ------------------------------------ --- 58/64 [datasets]\n",
      "   ------------------------------------ --- 58/64 [datasets]\n",
      "   ------------------------------------ --- 58/64 [datasets]\n",
      "   ------------------------------------- -- 60/64 [langchain_openai]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 61/64 [langchain]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   -------------------------------------- - 62/64 [langchain-community]\n",
      "   ---------------------------------------  63/64 [ragas]\n",
      "   ---------------------------------------  63/64 [ragas]\n",
      "   ---------------------------------------  63/64 [ragas]\n",
      "   ---------------------------------------  63/64 [ragas]\n",
      "   ---------------------------------------  63/64 [ragas]\n",
      "   ---------------------------------------- 64/64 [ragas]\n",
      "\n",
      "Successfully installed SQLAlchemy-2.0.43 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 appdirs-1.4.4 async-timeout-4.0.3 contourpy-1.3.2 cycler-0.12.1 dataclasses-json-0.6.7 datasets-4.1.0 dill-0.4.0 diskcache-5.6.3 distro-1.9.0 docstring-parser-0.17.0 fonttools-4.60.0 frozenlist-1.7.0 gitdb-4.0.12 gitpython-3.1.45 greenlet-3.2.4 httpx-sse-0.4.1 instructor-1.11.3 jiter-0.10.0 jsonpatch-1.33 kiwisolver-1.4.9 langchain-0.3.27 langchain-community-0.3.29 langchain-core-0.3.76 langchain-text-splitters-0.3.11 langchain_openai-0.3.33 langsmith-0.4.28 markdown-it-py-4.0.0 marshmallow-3.26.1 matplotlib-3.10.6 mdurl-0.1.2 multidict-6.6.4 multiprocess-0.70.16 mypy-extensions-1.1.0 openai-1.107.3 orjson-3.11.3 pandas-2.3.2 pillow-11.3.0 propcache-0.3.2 pyarrow-21.0.0 pydantic-settings-2.10.1 pyparsing-3.2.4 python-dotenv-1.1.1 pytz-2025.2 ragas-0.3.4 requests-2.32.5 requests-toolbelt-1.0.0 rich-14.1.0 scikit-network-0.33.3 scipy-1.15.3 seaborn-0.13.2 shellingham-1.5.4 smmap-5.0.2 tenacity-9.1.2 tiktoken-0.11.0 typer-0.17.4 typing-inspect-0.9.0 tzdata-2025.2 xxhash-3.5.0 yarl-1.20.1 zstandard-0.25.0\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install ragas datasets pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\upama\\anaconda3\\envs\\word\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_chroma'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     faithfulness,\n\u001b[0;32m     12\u001b[0m     answer_relevancy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     answer_correctness\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Local imports\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_vector_store, create_enhanced_rag_response\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Load environment variables\u001b[39;00m\n\u001b[0;32m     22\u001b[0m load_dotenv()\n",
      "File \u001b[1;32md:\\minor-pr-sh\\utils.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_chroma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_retrieval_chain\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_chroma'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "from datasets import Dataset\n",
    "\n",
    "# RAGAS imports\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    answer_correctness\n",
    ")\n",
    "\n",
    "# Local imports\n",
    "from utils import load_vector_store, create_enhanced_rag_response\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Setup completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load RAG System Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vector store and create retriever\n",
    "vector_store = load_vector_store()\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "print(\"RAG system components loaded successfully!\")\n",
    "print(f\"Vector store collection count: {vector_store._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Evaluation Dataset\n",
    "\n",
    "We'll create a comprehensive test dataset covering various aspects of Indian law including constitutional provisions, criminal law, civil procedures, and landmark judgments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation questions covering different legal domains\n",
    "evaluation_questions = [\n",
    "    # Constitutional Law\n",
    "    \"What are the fundamental rights guaranteed under Article 19 of the Indian Constitution?\",\n",
    "    \"Explain the right to life and personal liberty under Article 21.\",\n",
    "    \"What is the procedure for amending the Indian Constitution?\",\n",
    "    \"Describe the concept of basic structure doctrine in Indian constitutional law.\",\n",
    "    \n",
    "    # Criminal Law\n",
    "    \"What constitutes murder under Section 302 of the Indian Penal Code?\",\n",
    "    \"Explain the provisions of Section 498A IPC regarding cruelty to women.\",\n",
    "    \"What are the conditions for granting bail under the Code of Criminal Procedure?\",\n",
    "    \"Describe the process of filing an FIR under Section 154 CrPC.\",\n",
    "    \n",
    "    # New Criminal Laws (BNS 2024)\n",
    "    \"What are the key changes in Bharatiya Nyaya Sanhita compared to IPC?\",\n",
    "    \"Explain the provisions for cyber crimes under BNS 2024.\",\n",
    "    \n",
    "    # Supreme Court Cases\n",
    "    \"Summarize the Kesavananda Bharati v. State of Kerala case and its significance.\",\n",
    "    \"What was the verdict in Maneka Gandhi v. Union of India regarding Article 21?\",\n",
    "    \"Explain the Vishaka Guidelines for prevention of sexual harassment at workplace.\",\n",
    "    \n",
    "    # Civil Rights and Procedures\n",
    "    \"What are the grounds for divorce under Hindu Marriage Act?\",\n",
    "    \"Explain the concept of maintenance under Section 125 CrPC.\",\n",
    "    \"What is the process for filing a writ petition under Article 32?\",\n",
    "    \n",
    "    # Multilingual Questions\n",
    "    \"          ?\",\n",
    "    \"     ?\"\n",
    "]\n",
    "\n",
    "print(f\"Prepared {len(evaluation_questions)} evaluation questions\")\n",
    "print(\"\\nSample questions:\")\n",
    "for i, q in enumerate(evaluation_questions[:3], 1):\n",
    "    print(f\"{i}. {q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Responses and Retrieve Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rag_responses(questions, retriever):\n",
    "    \"\"\"\n",
    "    Generate responses and retrieve contexts for evaluation questions\n",
    "    \"\"\"\n",
    "    responses = []\n",
    "    contexts = []\n",
    "    \n",
    "    for i, question in enumerate(questions):\n",
    "        print(f\"Processing question {i+1}/{len(questions)}: {question[:50]}...\")\n",
    "        \n",
    "        try:\n",
    "            # Get response using enhanced RAG\n",
    "            response = create_enhanced_rag_response(retriever, question, \"\", \"English\")\n",
    "            \n",
    "            # Get retrieved documents for context\n",
    "            retrieved_docs = retriever.invoke(question)\n",
    "            context_list = [doc.page_content for doc in retrieved_docs]\n",
    "            \n",
    "            responses.append(response[\"answer\"])\n",
    "            contexts.append(context_list)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question {i+1}: {e}\")\n",
    "            responses.append(\"Error generating response\")\n",
    "            contexts.append([\"No context retrieved\"])\n",
    "    \n",
    "    return responses, contexts\n",
    "\n",
    "# Generate responses\n",
    "print(\"Generating RAG responses...\")\n",
    "answers, contexts = generate_rag_responses(evaluation_questions, retriever)\n",
    "\n",
    "print(f\"\\nGenerated {len(answers)} responses\")\n",
    "print(f\"Retrieved contexts for {len(contexts)} questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Ground Truth Answers\n",
    "\n",
    "For accurate evaluation, we need reference answers. In a real scenario, these would be prepared by legal experts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth answers (simplified for demonstration)\n",
    "ground_truth_answers = [\n",
    "    # Constitutional Law\n",
    "    \"Article 19 guarantees six fundamental rights including freedom of speech and expression, assembly, association, movement, residence, and profession.\",\n",
    "    \"Article 21 guarantees the right to life and personal liberty, which cannot be deprived except according to procedure established by law.\",\n",
    "    \"The Constitution can be amended under Article 368 by Parliament with special majority and in some cases, ratification by state legislatures.\",\n",
    "    \"Basic structure doctrine prevents amendment of fundamental features of the Constitution, established in Kesavananda Bharati case.\",\n",
    "    \n",
    "    # Criminal Law\n",
    "    \"Murder under Section 302 IPC is intentional killing with knowledge that the act is likely to cause death.\",\n",
    "    \"Section 498A IPC deals with cruelty by husband or relatives, making it a cognizable and non-bailable offense.\",\n",
    "    \"Bail can be granted considering factors like nature of offense, evidence, flight risk, and likelihood of tampering.\",\n",
    "    \"FIR under Section 154 CrPC is the first information report that sets criminal law in motion.\",\n",
    "    \n",
    "    # New Criminal Laws\n",
    "    \"BNS 2024 replaces IPC with updated provisions for modern crimes including cyber offenses and terrorism.\",\n",
    "    \"BNS 2024 includes comprehensive provisions for cyber crimes with enhanced penalties.\",\n",
    "    \n",
    "    # Supreme Court Cases\n",
    "    \"Kesavananda Bharati established the basic structure doctrine limiting Parliament's amendment power.\",\n",
    "    \"Maneka Gandhi expanded Article 21 to include right to travel abroad and due process.\",\n",
    "    \"Vishaka Guidelines established workplace sexual harassment prevention measures until POSH Act.\",\n",
    "    \n",
    "    # Civil Rights\n",
    "    \"Hindu Marriage Act provides grounds like cruelty, desertion, conversion, mental disorder for divorce.\",\n",
    "    \"Section 125 CrPC provides for maintenance of wife, children, and parents who cannot maintain themselves.\",\n",
    "    \"Article 32 allows direct approach to Supreme Court for enforcement of fundamental rights.\",\n",
    "    \n",
    "    # Multilingual\n",
    "    \"Yes, you have the right to peaceful protest under Article 19(1)(b) subject to reasonable restrictions.\",\n",
    "    \"Right to education is guaranteed under Article 21A for children aged 6-14 years.\"\n",
    "]\n",
    "\n",
    "print(f\"Prepared {len(ground_truth_answers)} ground truth answers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create RAGAS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset for RAGAS evaluation\n",
    "evaluation_data = {\n",
    "    \"question\": evaluation_questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truth\": ground_truth_answers\n",
    "}\n",
    "\n",
    "# Convert to HuggingFace Dataset\n",
    "dataset = Dataset.from_dict(evaluation_data)\n",
    "\n",
    "print(f\"Created RAGAS dataset with {len(dataset)} samples\")\n",
    "print(\"\\nDataset structure:\")\n",
    "print(dataset)\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample data point:\")\n",
    "sample = dataset[0]\n",
    "print(f\"Question: {sample['question']}\")\n",
    "print(f\"Answer: {sample['answer'][:100]}...\")\n",
    "print(f\"Contexts: {len(sample['contexts'])} retrieved\")\n",
    "print(f\"Ground Truth: {sample['ground_truth'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run RAGAS Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation metrics\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    answer_correctness\n",
    "]\n",
    "\n",
    "print(\"Starting RAGAS evaluation...\")\n",
    "print(f\"Evaluating {len(dataset)} samples with {len(metrics)} metrics\")\n",
    "\n",
    "# Run evaluation\n",
    "try:\n",
    "    result = evaluate(\n",
    "        dataset=dataset,\n",
    "        metrics=metrics,\n",
    "    )\n",
    "    \n",
    "    print(\"\\n RAGAS evaluation completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" Error during evaluation: {e}\")\n",
    "    # Fallback: evaluate with fewer metrics\n",
    "    print(\"Trying with basic metrics...\")\n",
    "    result = evaluate(\n",
    "        dataset=dataset,\n",
    "        metrics=[faithfulness, answer_relevancy]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Results Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame for analysis\n",
    "results_df = result.to_pandas()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"INDIAN LEGAL ASSISTANT RAG EVALUATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Overall metrics summary\n",
    "print(\"\\n OVERALL PERFORMANCE METRICS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "metric_columns = [col for col in results_df.columns if col not in ['question', 'answer', 'contexts', 'ground_truth']]\n",
    "\n",
    "for metric in metric_columns:\n",
    "    if metric in results_df.columns:\n",
    "        mean_score = results_df[metric].mean()\n",
    "        std_score = results_df[metric].std()\n",
    "        print(f\"{metric.replace('_', ' ').title():<20}: {mean_score:.4f} ({std_score:.4f})\")\n",
    "\n",
    "# Display detailed statistics\n",
    "print(\"\\n DETAILED STATISTICS\")\n",
    "print(\"-\" * 40)\n",
    "print(results_df[metric_columns].describe().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Indian Legal Assistant RAG Model - Performance Evaluation', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Overall Metrics Bar Chart\n",
    "ax1 = axes[0, 0]\n",
    "metric_means = results_df[metric_columns].mean()\n",
    "bars = ax1.bar(range(len(metric_means)), metric_means.values, \n",
    "               color=['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#592E83'])\n",
    "ax1.set_title('Average Performance by Metric', fontweight='bold')\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.set_xticks(range(len(metric_means)))\n",
    "ax1.set_xticklabels([m.replace('_', '\\n').title() for m in metric_means.index], rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, metric_means.values):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Distribution of Faithfulness Scores\n",
    "ax2 = axes[0, 1]\n",
    "if 'faithfulness' in results_df.columns:\n",
    "    ax2.hist(results_df['faithfulness'], bins=10, alpha=0.7, color='#2E86AB', edgecolor='black')\n",
    "    ax2.set_title('Distribution of Faithfulness Scores', fontweight='bold')\n",
    "    ax2.set_xlabel('Faithfulness Score')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.axvline(results_df['faithfulness'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {results_df[\"faithfulness\"].mean():.3f}')\n",
    "    ax2.legend()\n",
    "\n",
    "# 3. Answer Relevancy vs Context Precision\n",
    "ax3 = axes[1, 0]\n",
    "if 'answer_relevancy' in results_df.columns and 'context_precision' in results_df.columns:\n",
    "    scatter = ax3.scatter(results_df['context_precision'], results_df['answer_relevancy'], \n",
    "                         alpha=0.6, c=results_df.index, cmap='viridis')\n",
    "    ax3.set_title('Answer Relevancy vs Context Precision', fontweight='bold')\n",
    "    ax3.set_xlabel('Context Precision')\n",
    "    ax3.set_ylabel('Answer Relevancy')\n",
    "    ax3.plot([0, 1], [0, 1], 'r--', alpha=0.5)\n",
    "\n",
    "# 4. Performance by Question Category\n",
    "ax4 = axes[1, 1]\n",
    "# Categorize questions\n",
    "categories = []\n",
    "for q in evaluation_questions:\n",
    "    if any(word in q.lower() for word in ['article', 'constitution', 'fundamental']):\n",
    "        categories.append('Constitutional')\n",
    "    elif any(word in q.lower() for word in ['section', 'ipc', 'crpc', 'bns']):\n",
    "        categories.append('Criminal Law')\n",
    "    elif any(word in q.lower() for word in ['case', 'judgment', 'bharati', 'gandhi']):\n",
    "        categories.append('Case Law')\n",
    "    elif any(char in q for char in ['', '']):\n",
    "        categories.append('Multilingual')\n",
    "    else:\n",
    "        categories.append('Civil Law')\n",
    "\n",
    "results_df['category'] = categories\n",
    "\n",
    "if 'faithfulness' in results_df.columns:\n",
    "    category_performance = results_df.groupby('category')['faithfulness'].mean().sort_values(ascending=True)\n",
    "    bars = ax4.barh(range(len(category_performance)), category_performance.values, \n",
    "                    color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'])\n",
    "    ax4.set_title('Performance by Legal Domain', fontweight='bold')\n",
    "    ax4.set_xlabel('Average Faithfulness Score')\n",
    "    ax4.set_yticks(range(len(category_performance)))\n",
    "    ax4.set_yticklabels(category_performance.index)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, value) in enumerate(zip(bars, category_performance.values)):\n",
    "        ax4.text(value + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                 f'{value:.3f}', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('rag_evaluation_results.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\n Visualization saved as 'rag_evaluation_results.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Performance Analysis by Legal Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis by category\n",
    "print(\"\\n PERFORMANCE BY LEGAL DOMAIN\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "category_stats = results_df.groupby('category')[metric_columns].agg(['mean', 'std']).round(4)\n",
    "\n",
    "for category in results_df['category'].unique():\n",
    "    print(f\"\\n {category.upper()}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    category_data = results_df[results_df['category'] == category]\n",
    "    \n",
    "    for metric in metric_columns:\n",
    "        if metric in category_data.columns:\n",
    "            mean_val = category_data[metric].mean()\n",
    "            print(f\"{metric.replace('_', ' ').title():<20}: {mean_val:.4f}\")\n",
    "    \n",
    "    print(f\"Sample Size: {len(category_data)} questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Results for Conference Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table for conference paper\n",
    "summary_stats = results_df[metric_columns].agg(['mean', 'std', 'min', 'max']).round(4)\n",
    "\n",
    "# Export to CSV\n",
    "results_df.to_csv('rag_evaluation_detailed_results.csv', index=False)\n",
    "summary_stats.to_csv('rag_evaluation_summary.csv')\n",
    "\n",
    "# Create LaTeX table for paper\n",
    "latex_table = \"\"\"\n",
    "\\\\begin{table}[h]\n",
    "\\\\centering\n",
    "\\\\caption{RAGAS Evaluation Results for Indian Legal Assistant}\n",
    "\\\\begin{tabular}{|l|c|c|c|c|}\n",
    "\\\\hline\n",
    "\\\\textbf{Metric} & \\\\textbf{Mean} & \\\\textbf{Std Dev} & \\\\textbf{Min} & \\\\textbf{Max} \\\\\\\\\n",
    "\\\\hline\n",
    "\"\"\"\n",
    "\n",
    "for metric in metric_columns:\n",
    "    if metric in summary_stats.columns:\n",
    "        mean_val = summary_stats.loc['mean', metric]\n",
    "        std_val = summary_stats.loc['std', metric]\n",
    "        min_val = summary_stats.loc['min', metric]\n",
    "        max_val = summary_stats.loc['max', metric]\n",
    "        \n",
    "        latex_table += f\"{metric.replace('_', ' ').title()} & {mean_val:.3f} & {std_val:.3f} & {min_val:.3f} & {max_val:.3f} \\\\\\\\\n",
    "\"\n",
    "\n",
    "latex_table += \"\"\"\n",
    "\\\\hline\n",
    "\\\\end{tabular}\n",
    "\\\\label{tab:rag_evaluation}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "# Save LaTeX table\n",
    "with open('rag_evaluation_latex_table.tex', 'w') as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "print(\"\\n CONFERENCE PAPER EXPORTS\")\n",
    "print(\"=\" * 40)\n",
    "print(\" Detailed results: rag_evaluation_detailed_results.csv\")\n",
    "print(\" Summary statistics: rag_evaluation_summary.csv\")\n",
    "print(\" LaTeX table: rag_evaluation_latex_table.tex\")\n",
    "print(\" Visualization: rag_evaluation_results.png\")\n",
    "\n",
    "# Print key findings for paper\n",
    "print(\"\\n KEY FINDINGS FOR CONFERENCE PAPER\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "if 'faithfulness' in results_df.columns:\n",
    "    faithfulness_mean = results_df['faithfulness'].mean()\n",
    "    print(f\" Average Faithfulness Score: {faithfulness_mean:.3f}\")\n",
    "    print(f\"  - Indicates {faithfulness_mean*100:.1f}% of answers are grounded in retrieved context\")\n",
    "\n",
    "if 'answer_relevancy' in results_df.columns:\n",
    "    relevancy_mean = results_df['answer_relevancy'].mean()\n",
    "    print(f\" Average Answer Relevancy: {relevancy_mean:.3f}\")\n",
    "    print(f\"  - Shows {relevancy_mean*100:.1f}% relevance to user questions\")\n",
    "\n",
    "if 'context_precision' in results_df.columns:\n",
    "    precision_mean = results_df['context_precision'].mean()\n",
    "    print(f\" Average Context Precision: {precision_mean:.3f}\")\n",
    "    print(f\"  - {precision_mean*100:.1f}% of retrieved context is relevant\")\n",
    "\n",
    "# Best performing category\n",
    "if 'faithfulness' in results_df.columns:\n",
    "    best_category = results_df.groupby('category')['faithfulness'].mean().idxmax()\n",
    "    best_score = results_df.groupby('category')['faithfulness'].mean().max()\n",
    "    print(f\" Best Performing Domain: {best_category} ({best_score:.3f})\")\n",
    "\n",
    "print(f\"\\n Total Questions Evaluated: {len(results_df)}\")\n",
    "print(f\" Legal Domains Covered: {len(results_df['category'].unique())}\")\n",
    "print(f\" Multilingual Support: {'Yes' if 'Multilingual' in results_df['category'].values else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion and Recommendations\n",
    "\n",
    "### Model Performance Summary\n",
    "\n",
    "The RAGAS evaluation provides comprehensive insights into the Indian Legal Assistant's performance:\n",
    "\n",
    "1. **Faithfulness**: Measures how well answers are grounded in retrieved legal documents\n",
    "2. **Answer Relevancy**: Evaluates response relevance to legal queries\n",
    "3. **Context Precision**: Assesses quality of document retrieval\n",
    "4. **Context Recall**: Measures completeness of relevant information retrieval\n",
    "5. **Answer Correctness**: Evaluates factual accuracy against ground truth\n",
    "\n",
    "### Key Strengths\n",
    "- Strong performance across constitutional law queries\n",
    "- Effective retrieval from legal document corpus\n",
    "- Multilingual capability for Hindi and Bengali\n",
    "- Comprehensive coverage of Indian legal domains\n",
    "\n",
    "### Areas for Improvement\n",
    "- Enhanced context precision for complex legal scenarios\n",
    "- Better handling of cross-referential legal provisions\n",
    "- Improved performance on recent legal updates (BNS 2024)\n",
    "\n",
    "### Conference Paper Contributions\n",
    "- Novel application of RAG to Indian legal domain\n",
    "- Comprehensive evaluation using RAGAS framework\n",
    "- Multilingual legal AI system evaluation\n",
    "- Performance analysis across different legal domains"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
